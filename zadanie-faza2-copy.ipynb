{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "642d43bb",
   "metadata": {},
   "source": [
    "#   IAU Zadanie - II. fáza\n",
    "\n",
    "### Autori: Peter Brandajsky - 50%, Frederik Duvač - 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a381b8",
   "metadata": {},
   "source": [
    "# Načítanie údajov z datasetu\n",
    "\n",
    "Dataset sme si exportli, nakonci fázy 1, kde sme spojili **connections_mean_median** a **processes_mean_median** na **imei** a **ts** stĺpcoch, čo boli naše upravené datasety s imputáciou missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff54a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "dataset = pd.read_csv('dataset/dataset_phase_2.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb1a20",
   "metadata": {},
   "source": [
    "Atributy pri ktorých nebola ziadna korelacia, sme kompletne vyradili do dalsej manipulacie s datasetom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\n",
    "    ['mwra', 'c.android.gm', 'c.android.chrome', 'c.dogalize', 'c.katana', 'c.android.youtube', 'p.android.documentsui',\n",
    "     'p.system', 'p.android.chrome', 'p.android.externalstorage',\n",
    "     'p.android.gm', 'p.android.packageinstaller', 'p.olauncher']]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(dataset.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Korelačná matica: mwra a prediktory', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd01b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2fe95",
   "metadata": {},
   "source": [
    "# 2.1 Realizácia predspracovania dát\n",
    "\n",
    "## 2.1.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04338a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "    dataset,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dataset['mwra']  # Toto zabezpečí rovnakú distribúciu tried\n",
    ")\n",
    "\n",
    "# Kontrola distribúcie tried\n",
    "print(\"Kontrola distribúcie tried:\\n\")\n",
    "print(\"Pôvodný dataset:\")\n",
    "print(dataset['mwra'].value_counts(normalize=True).round(6))\n",
    "\n",
    "print(\"\\nTrénovacia množina:\")\n",
    "print(train_data['mwra'].value_counts(normalize=True).round(6))\n",
    "\n",
    "print(\"\\nTestovacia množina:\")\n",
    "print(test_data['mwra'].value_counts(normalize=True).round(6))\n",
    "\n",
    "# Kontrola absolútnych počtov\n",
    "print(\"\\nAbsolútne počty:\")\n",
    "print(f\"Celkový počet vzoriek: {len(dataset)}\")\n",
    "print(f\"Počet trénovacích vzoriek: {len(train_data)} ({len(train_data) / len(dataset) * 100:.1f}%)\")\n",
    "print(f\"Počet testovacích vzoriek: {len(test_data)} ({len(test_data) / len(dataset) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951c136",
   "metadata": {},
   "source": [
    "## 2.1.B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848660e7",
   "metadata": {},
   "source": [
    "#### Kontrola formátu dát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Počet pozorovaní (riadkov): {len(train_data)}\")\n",
    "print(f\"Počet atribútov (stĺpcov): {len(train_data.columns)}\")\n",
    "print(\"\\nTypy dát v stĺpcoch:\")\n",
    "print(train_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef0d72",
   "metadata": {},
   "source": [
    "Vidime ze vsetky data mame numericke takze nepotrebujeme robit ziaden encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9665c6",
   "metadata": {},
   "source": [
    "#### Kontrola chýbajúcich hodnôt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a67dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKontrola chýbajúcich hodnôt:\")\n",
    "missing_values = train_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.any():\n",
    "    print(\"\\nNahradzovanie chýbajúcich hodnôt:\")\n",
    "    # Pre numerické stĺpce použijeme medián\n",
    "    numeric_columns = train_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    for col in numeric_columns:\n",
    "        if missing_values[col] > 0:\n",
    "            median_value = train_data[col].median()\n",
    "            train_data[col].fillna(median_value, inplace=True)\n",
    "            print(f\"Stĺpec {col}: nahradených {missing_values[col]} hodnôt mediánom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729bafc2",
   "metadata": {},
   "source": [
    "Dataset neobsahuje ziadne chybajuce hodnoty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b462a72",
   "metadata": {},
   "source": [
    "#### Kontrola a spracovanie outlierov pomocou IQR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získanie počtu stĺpcov, ktoré chceme vizualizovať\n",
    "num_columns = len(train_data.drop('mwra', axis=1).columns)\n",
    "\n",
    "# Dynamické nastavenie počtu riadkov a stĺpcov pre mriežku grafov\n",
    "cols = 2\n",
    "rows = np.ceil(num_columns / cols).astype(int)  # zaokrúhlenie nahor\n",
    "\n",
    "plt.figure(figsize=(12, 20))\n",
    "for i, column in enumerate(train_data.drop('mwra', axis=1).columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(data=train_data, x=column, kde=True)\n",
    "    plt.title(f'Distribúcia {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22f036",
   "metadata": {},
   "source": [
    "V prvej faze sme risili odstraneni outlierov a nahradenie nan hodnot priemerom alebo medianom. Data po rozdeleni ukazuju nejakych outlierov tak ich nahradime technikou winsorization, cize hranicnymi hodnotami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab142940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Počet outlierov\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    print(f\"\\nStĺpec {column}:\")\n",
    "    print(f\"Počet outlierov: {len(outliers)}\")\n",
    "    print(f\"Percento outlierov: {(len(outliers) / len(df) * 100):.2f}%\")\n",
    "\n",
    "    # Nahradenie outlierov hraničnými hodnotami\n",
    "    df.loc[df[column] < lower_bound, column] = lower_bound\n",
    "    df.loc[df[column] > upper_bound, column] = upper_bound\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Spracovanie outlierov pre každý numerický stĺpec okrem target premennej\n",
    "print(\"\\nSpracovanie outlierov:\")\n",
    "for column in train_data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    if column != 'mwra':\n",
    "        train_data = handle_outliers(train_data, column)\n",
    "\n",
    "print(f\"\\nPočet riadkov po odstránení outlierov: {len(train_data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bac471",
   "metadata": {},
   "source": [
    "#### Kontrola vyslednych dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nKontrola výsledných dát:\")\n",
    "print(\"\\nZákladné štatistiky:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "print(\"\\nKontrolné body:\")\n",
    "print(f\"- Počet pozorovaní (riadkov): {len(train_data)}\")\n",
    "print(f\"- Počet atribútov (stĺpcov): {len(train_data.columns)}\")\n",
    "print(\"- Všetky atribúty sú numerické:\", all(train_data.dtypes.apply(lambda x: np.issubdtype(x, np.number))))\n",
    "print(\"- Žiadne chýbajúce hodnoty:\", not train_data.isnull().any().any())\n",
    "\n",
    "# Získanie počtu stĺpcov, ktoré chceme vizualizovať\n",
    "num_columns = len(train_data.drop('mwra', axis=1).columns)\n",
    "\n",
    "# Dynamické nastavenie počtu riadkov a stĺpcov pre mriežku grafov\n",
    "cols = 2\n",
    "rows = np.ceil(num_columns / cols).astype(int)  # zaokrúhlenie nahor\n",
    "\n",
    "plt.figure(figsize=(12, 20))\n",
    "for i, column in enumerate(train_data.drop('mwra', axis=1).columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(data=train_data, x=column, kde=True)\n",
    "    plt.title(f'Distribúcia {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5748b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získanie počtu stĺpcov, ktoré chceme vizualizovať\n",
    "num_columns = len(train_data.drop('mwra', axis=1).columns)\n",
    "\n",
    "# Dynamické nastavenie počtu riadkov a stĺpcov pre mriežku grafov\n",
    "cols = 2\n",
    "rows = np.ceil(num_columns / cols).astype(int)  # zaokrúhlenie nahor\n",
    "\n",
    "plt.figure(figsize=(12, 20))\n",
    "for i, column in enumerate(train_data.drop('mwra', axis=1).columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.boxplot(data=train_data, x=column)\n",
    "    plt.title(f'Distribúcia {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f614d46",
   "metadata": {},
   "source": [
    "## 2.1.C - Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcaab1",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vykreslenie histogramov a Q-Q plotov\n",
    "for column in train_data.drop('mwra', axis=1).columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(train_data[column], kde=True)\n",
    "    plt.title(f'Histogram: {column}')\n",
    "\n",
    "    # Q-Q plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    stats.probplot(train_data[column], dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot: {column}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fae8b",
   "metadata": {},
   "source": [
    "Z histogramov a qq plotov vidime ze data mame priblizne gaussian a p.launcher nie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4047ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stĺpce podľa typu rozdelenia\n",
    "normal_columns = ['c.android.gm', 'c.android.chrome', 'c.dogalize', 'c.katana',\n",
    "                  'c.android.youtube', 'p.android.documentsui', 'p.system',\n",
    "                  'p.android.chrome', 'p.android.externalstorage', 'p.android.gm',\n",
    "                  'p.android.packageinstaller']\n",
    "\n",
    "skewed_columns = ['p.olauncher']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4824fee",
   "metadata": {},
   "source": [
    "Vo všeobecnosti by sa transformácia mala vykonať pred škálovaním. Hlavný dôvod je ten, že transformácia údajov (napríklad pomocou log, Power alebo Quantile Transformácie) zmení ich distribúciu. Škálovanie následne upraví dáta do požadovaného rozsahu alebo štandardného rozloženia, čo je obzvlášť dôležité pri modeloch, ktoré sú citlivé na rozsah hodnôt.\n",
    "\n",
    "Poradie:\n",
    "\n",
    "1. Transformácia: Najprv vykonáme transformáciu, ktorá zlepšuje symetriu alebo normalitu dát.\n",
    "2. Škálovanie: Potom aplikujeme škálovanie, ktoré prispôsobí hodnoty do rovnakého rozsahu alebo na štandardnú mierku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ada82",
   "metadata": {},
   "source": [
    "#### 1. Transformácia (Quantile a Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd376e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile transformácia pre zmenu na normalovu distribuciu\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state=0)\n",
    "train_data_quantile_transformed = train_data.copy()\n",
    "train_data_quantile_transformed[skewed_columns] = quantile_transformer.fit_transform(train_data[skewed_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power transformácia pre približne normálne rozdelené atribúty\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "train_data_power_transformed = train_data.copy()\n",
    "train_data_power_transformed[normal_columns] = power_transformer.fit_transform(train_data[normal_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa65cd",
   "metadata": {},
   "source": [
    "#### 2. Škálovanie (Standard a Min-Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0e80d",
   "metadata": {},
   "source": [
    "Oba typy škálovania majú svoje výhody a vhodnosť použitia závisí od zvoleného modelu a typu dát. **Min-Max Scaling** je vhodný na škálovanie do pevného rozsahu (napr. 0 až 1), zatiaľ čo **Standard Scaling** je užitočný, ak potrebujeme normalizovať atribúty do symetrického rozsahu okolo 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling pre normálne rozdelené atribúty\n",
    "standard_scaler = StandardScaler()\n",
    "train_data_standard_scaled = train_data_power_transformed.copy()  # použijeme transformované údaje z Power Transformácie\n",
    "train_data_standard_scaled[normal_columns] = standard_scaler.fit_transform(train_data_power_transformed[normal_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling pre silne šikmý atribút\n",
    "minmax_scaler = MinMaxScaler()\n",
    "train_data_minmax_scaled = train_data_quantile_transformed.copy()  # použijeme transformované údaje z Quantile Transformácie\n",
    "train_data_minmax_scaled[skewed_columns] = minmax_scaler.fit_transform(train_data_quantile_transformed[skewed_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06baed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard Scaling on Power Transformed data for normal columns:\")\n",
    "print(train_data_standard_scaled[normal_columns].head())\n",
    "\n",
    "print(\"\\nMin-Max Scaling on Quantile Transformed skewed column:\")\n",
    "print(train_data_minmax_scaled[skewed_columns].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d83f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Získanie počtu stĺpcov, ktoré chceme vizualizovať\n",
    "num_columns = len(train_data.drop('mwra', axis=1).columns)\n",
    "\n",
    "# Dynamické nastavenie počtu riadkov a stĺpcov pre mriežku grafov\n",
    "cols = 4\n",
    "rows = np.ceil(num_columns / cols).astype(int)  # zaokrúhlenie nahor\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, column in enumerate(train_data.drop('mwra', axis=1).columns):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(data=train_data, x=column, kde=True)\n",
    "    plt.title(f'Distribúcia {column}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b20cc99",
   "metadata": {},
   "source": [
    "## 2.1.D - Zhrnutie\n",
    "\n",
    "1. **Poradie:** Najskôr sme aplikovali transformáciu (Quantile alebo Power) a potom škálovanie.\n",
    "2. **Výber transformácií a škálovania:**\n",
    "    - Standard Scaling je ideálny pre atribúty, ktoré majú približne normálne rozdelenie, zatiaľ čo Min-Max Scaling je vhodný pre atribúty s veľkým rozsahom hodnôt a šikmosťou.\n",
    "    - Quantile Transformácia a Power Transformácia (Yeo-Johnson) zlepšujú symetriu a normalitu dát.\n",
    "\n",
    "Tento prístup pripraví dáta na efektívne využitie v modeloch strojového učenia a pomôže zlepšiť stabilitu modelov, najmä pri algoritmoch citlivých na rozsah hodnôt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf9a81e",
   "metadata": {},
   "source": [
    "# 2.2 Výber atribútov pre strojové učenie\n",
    "\n",
    "## 2.2.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9330b",
   "metadata": {},
   "source": [
    "Použil som 4 rôzne techniky na určenie dôležitosti features:\n",
    "\n",
    "1. Korelačná analýza\n",
    "\n",
    "    Meria lineárny vzťah medzi každým feature a cieľovou premennou<br>\n",
    "    Výhody: Jednoduchá interpretácia<br>\n",
    "    Nevýhody: Zachytí len lineárne vzťahy\n",
    "\n",
    "\n",
    "2. Mutual Information\n",
    "\n",
    "    Meria ako veľa informácie poskytuje feature o cieľovej premennej<br>\n",
    "    Výhody: Zachytí aj nelineárne vzťahy<br>\n",
    "    Nevýhody: Hodnoty sú ťažšie interpretovateľné\n",
    "\n",
    "\n",
    "3. ANOVA F-value\n",
    "\n",
    "    Testuje štatistickú významnosť rozdielov medzi skupinami<br>\n",
    "    Výhody: Štatisticky podložené<br>\n",
    "    Nevýhody: Predpokladá normálne rozdelenie\n",
    "\n",
    "\n",
    "4. Random Forest Feature Importance\n",
    "\n",
    "    Meria dôležitosť features na základe ich vplyvu na presnosť modelu<br>\n",
    "    Výhody: Zachytí interakcie medzi features<br>\n",
    "    Nevýhody: Môže byť ovplyvnená korelovanými features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rozdelenie na features a target\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "\n",
    "X = train_data.drop('mwra', axis=1)\n",
    "y = train_data['mwra']\n",
    "\n",
    "# 1. Korelačná analýza\n",
    "print(\"1. Korelačná analýza:\")\n",
    "correlation_with_target = X.apply(lambda x: x.corr(y))\n",
    "print(\"\\nKorelácia s cieľovou premennou:\")\n",
    "print(correlation_with_target.sort_values(ascending=False))\n",
    "\n",
    "# Vizualizácia korelácií\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation_with_target.sort_values().plot(kind='bar')\n",
    "plt.title('Korelácia features s cieľovou premennou')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Mutual Information\n",
    "print(\"\\n2. Mutual Information Score:\")\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "mi_scores = pd.Series(mi_scores, index=X.columns)\n",
    "print(mi_scores.sort_values(ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "mi_scores.sort_values().plot(kind='bar')\n",
    "plt.title('Mutual Information Scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. ANOVA F-value\n",
    "print(\"\\n3. ANOVA F-value:\")\n",
    "f_scores = f_classif(X, y)[0]\n",
    "f_scores = pd.Series(f_scores, index=X.columns)\n",
    "print(f_scores.sort_values(ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "f_scores.sort_values().plot(kind='bar')\n",
    "plt.title('ANOVA F-scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Random Forest Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "rf_importance = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(\"\\n4. Random Forest Feature Importance:\")\n",
    "print(rf_importance.sort_values(ascending=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "rf_importance.sort_values().plot(kind='bar')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Porovnanie výsledkov všetkých metód\n",
    "results = pd.DataFrame({\n",
    "    'Correlation': abs(correlation_with_target),\n",
    "    'Mutual_Information': mi_scores,\n",
    "    'ANOVA_F_Score': f_scores,\n",
    "    'RF_Importance': rf_importance\n",
    "})\n",
    "\n",
    "# Normalizácia hodnôt pre lepšie porovnanie\n",
    "scaler = StandardScaler()\n",
    "results_normalized = pd.DataFrame(\n",
    "    scaler.fit_transform(results),\n",
    "    columns=results.columns,\n",
    "    index=results.index\n",
    ")\n",
    "\n",
    "# Vizualizácia porovnania\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "results_normalized.plot(kind='bar')\n",
    "plt.title('Porovnanie dôležitosti features podľa rôznych metód')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\nSúhrnné poradie features podľa všetkých metód:\")\n",
    "\n",
    "# Priemerné normalizované skóre\n",
    "average_importance = results_normalized.mean(axis=1).sort_values(ascending=False)\n",
    "print(average_importance)\n",
    "\n",
    "# Vytvorenie heatmapy pre lepšiu vizualizáciu\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(results_normalized.T, annot=True, cmap='YlOrRd')\n",
    "plt.title('Heatmapa dôležitosti features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a46b5",
   "metadata": {},
   "source": [
    "## 2.2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb71291",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_importance = results.mean(axis=1).sort_values()\n",
    "\n",
    "# Vizualizácia\n",
    "plt.figure(figsize=(10, 6))\n",
    "average_importance.plot(kind='barh')\n",
    "plt.title('Dôležitosť features (väčšia hodnota = väčšia dôležitosť)')\n",
    "plt.xlabel('Priemerná dôležitosť')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d23a118",
   "metadata": {},
   "source": [
    "## 2.2.C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d3d41",
   "metadata": {},
   "source": [
    "### 1. Korelačná analýza\n",
    "Dôvod výberu: \n",
    "- Jednoduchá a rýchla metóda na identifikáciu lineárnych vzťahov\n",
    "- Hodnoty od -1 do 1 sú ľahko interpretovateľné\n",
    "- Umožňuje odhaliť priame aj nepriame lineárne závislosti\n",
    "<br><br>\n",
    "- Výhody:\n",
    "   - Rýchly výpočet\n",
    "   - Ľahká interpretácia\n",
    "- Nevýhody:\n",
    "   - Zachytí len lineárne vzťahy\n",
    "   - Citlivá na outliery\n",
    "\n",
    "### 2. Mutual Information\n",
    "Dôvod výberu:\n",
    "- Meria všeobecnú závislosť (aj nelineárnu)\n",
    "- Vhodná pre klasifikačné úlohy\n",
    "- Nezávislá na škálovaní dát\n",
    "<br><br>\n",
    "- Výhody:\n",
    "   - Zachytí aj nelineárne vzťahy\n",
    "   - Robustná voči outlierom  \n",
    "- Nevýhody:\n",
    "   - Náročnejšia interpretácia hodnôt\n",
    "   - Výpočtovo náročnejšia\n",
    "\n",
    "### 3. ANOVA F-value\n",
    "Dôvod výberu:\n",
    "- Štatisticky podložená metóda\n",
    "- Testuje rozdiely medzi skupinami\n",
    "- Vhodná pre klasifikačné úlohy\n",
    "<br><br>\n",
    "- Výhody:\n",
    "   - Štatisticky robustná\n",
    "- Nevýhody:\n",
    "   - Predpokladá normálne rozdelenie\n",
    "   - Citlivá na veľkosť vzorky\n",
    "\n",
    "### 4. Random Forest Feature Importance\n",
    "Dôvod výberu:\n",
    "- Založená na reálnom modeli strojového učenia\n",
    "- Berie do úvahy interakcie medzi premennými\n",
    "- Robustná voči outlierom a chýbajúcim hodnotám\n",
    "<br><br>\n",
    "- Výhody:\n",
    "   - Zachytí komplexné vzťahy\n",
    "   - Priamo súvisí s predikčnou silou\n",
    "- Nevýhody:\n",
    "   - Výpočtovo náročná\n",
    "   - Môže byť ovplyvnená korelovanými features\n",
    "\n",
    "### Normalizácia a porovnanie\n",
    "Dôvod použitia StandardScaler:\n",
    "- Rôzne metriky majú rôzne škály\n",
    "- Normalizácia umožňuje priame porovnanie\n",
    "- Štandardizované skóre sú ľahšie porovnateľné\n",
    "\n",
    "Dôvod použitia viacerých vizualizácií:\n",
    "1. Bar plots pre jednotlivé metódy:\n",
    "   - Prehľadné zobrazenie poradia\n",
    "   - Ľahko čitateľné jednotlivé hodnoty\n",
    "\n",
    "2. Heatmapa:\n",
    "   - Kompaktné zobrazenie všetkých metód\n",
    "   - Farebné kódovanie pre rýchlu orientáciu\n",
    "   - Možnosť vidieť vzory medzi metódami\n",
    "\n",
    "3. Priemerná dôležitosť:\n",
    "   - Sumarizácia všetkých metód\n",
    "   - Konečné poradie features\n",
    "   - Jednoduchá interpretácia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2857554",
   "metadata": {},
   "source": [
    "# 2.3 Replikovateľnosť predspracovania\n",
    "\n",
    "## 2.3.A & 2.3.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer, PowerTransformer, StandardScaler, MinMaxScaler, FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Definícia stĺpcov\n",
    "normal_columns = [\n",
    "    'c.android.gm', 'c.android.chrome', 'c.dogalize', 'c.katana',\n",
    "    'c.android.youtube', 'p.android.documentsui', 'p.system',\n",
    "    'p.android.chrome', 'p.android.externalstorage', 'p.android.gm',\n",
    "    'p.android.packageinstaller'\n",
    "]\n",
    "skewed_column = ['p.olauncher']\n",
    "\n",
    "X_train = train_data.drop(columns=['mwra'])\n",
    "y_train = train_data['mwra']\n",
    "X_test = test_data.drop(columns=['mwra'])\n",
    "y_test = test_data['mwra']\n",
    "\n",
    "# Krok 1: Quantile Transformácia pre šikmý stĺpec\n",
    "quantile_transformer = Pipeline(steps=[\n",
    "    ('transform', make_column_transformer(\n",
    "        (QuantileTransformer(output_distribution=\"normal\", random_state=42), skewed_column),\n",
    "        remainder='passthrough')),\n",
    "    ('to_dataframe', FunctionTransformer(lambda x: pd.DataFrame(x, columns=X_train.columns)))\n",
    "])\n",
    "\n",
    "# Krok 2: Power Transformácia pre normálne stĺpce\n",
    "power_transformer = Pipeline(steps=[\n",
    "    ('transform', make_column_transformer(\n",
    "        (PowerTransformer(method='yeo-johnson', standardize=True), normal_columns),\n",
    "        remainder='passthrough')),\n",
    "    ('to_dataframe', FunctionTransformer(lambda x: pd.DataFrame(x, columns=X_train.columns)))\n",
    "])\n",
    "\n",
    "# Krok 3: Standard Scaling pre normálne stĺpce\n",
    "standard_scaler = Pipeline(steps=[\n",
    "    ('transform', make_column_transformer(\n",
    "        (StandardScaler(), normal_columns),\n",
    "        remainder='passthrough')),\n",
    "    ('to_dataframe', FunctionTransformer(lambda x: pd.DataFrame(x, columns=X_train.columns)))\n",
    "])\n",
    "\n",
    "# Krok 4: Min-Max Scaling pre šikmý stĺpec\n",
    "minmax_scaler = Pipeline(steps=[\n",
    "    ('transform', make_column_transformer(\n",
    "        (MinMaxScaler(), skewed_column),\n",
    "        remainder='passthrough')),\n",
    "    ('to_dataframe', FunctionTransformer(lambda x: pd.DataFrame(x, columns=X_train.columns)))\n",
    "])\n",
    "\n",
    "# Vytvorenie hlavnej Pipeline s každým krokom zvlášť\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('quantile', quantile_transformer),\n",
    "    ('power', power_transformer),\n",
    "    ('scaler', standard_scaler),\n",
    "    ('minmax', minmax_scaler),\n",
    "], verbose=True)\n",
    "\n",
    "# Aplikácia pipeline na trénovacie dáta bez 'mwra'\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)\n",
    "\n",
    "# Spojenie transformovaných dát s cieľovým stĺpcom 'mwra'\n",
    "train_transformed = pd.concat([y_train.reset_index(drop=True), X_train_transformed], axis=1)\n",
    "test_transformed = pd.concat([y_test.reset_index(drop=True), pd.DataFrame(X_test_transformed, columns=X_test.columns)], axis=1)\n",
    "\n",
    "train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd20807",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930d04a",
   "metadata": {},
   "source": [
    "# Záver\n",
    "\n",
    "1. **Replikovateľnosť predspracovania:** Definovaním predspracovateľskej pipeline sme zabezpečili, že trénovacia aj testovacia množina prejdú rovnakými transformáciami a škálovaním, čo zaručuje konzistentnosť a umožňuje jednoduché opakovanie procesu na ďalších dátach.\n",
    "2. **Výhoda použitia sklearn.pipeline:** Pipeline nám umožňuje prehľadný a ľahko udržiavateľný kód, ktorý je pripravený na integráciu do modelovacieho procesu a opakovateľný pre nové dáta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f76c1",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed.to_csv('dataset/train_transformed.csv', sep='\\t', index=False, encoding='utf-8')\n",
    "test_transformed.to_csv('dataset/test_transformed.csv', sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "train_data.to_csv('dataset/train_data.csv', sep='\\t', index=False, encoding='utf-8')\n",
    "test_data.to_csv('dataset/test_data.csv', sep='\\t', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
